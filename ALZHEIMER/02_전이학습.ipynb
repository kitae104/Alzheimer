{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전이학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Input, models, layers, optimizers, metrics\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 학습셋의 변형을 설정하는 부분입니다.- 이미지 생성 옵션\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,          # 주어진 이미지의 크기를 설정합니다.\n",
    "                                  horizontal_flip=True,     # 수평 대칭 이미지를 50% 확률로 만들어 추가합니다.\n",
    "                                  width_shift_range=0.1,    # 전체 크기의 15% 범위에서 좌우로 이동합니다.\n",
    "                                  height_shift_range=0.1,   # 마찬가지로 위, 아래로 이동합니다.\n",
    "                                  #rotation_range=5,        # 정해진 각도만큼 회전시킵니다.\n",
    "                                  #shear_range=0.7,         # 좌표 하나를 고정시키고 나머지를 이동시킵니다.\n",
    "                                  #zoom_range=1.2,          # 확대 또는 축소시킵니다.\n",
    "                                  #vertical_flip=True,      # 수직 대칭 이미지를 만듭니다.\n",
    "                                  #fill_mode='nearest'      # 빈 공간을 채우는 방법입니다. nearest 옵션은 가장 비슷한 색으로 채우게 됩니다.\n",
    "                                  )\n",
    "\n",
    "# 실제 데이터가 있는 곳을 알려주고 이미지를 불러옴\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "       './image_data/train',   # 학습셋이 있는 폴더의 위치입니다.\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋은 이미지 부풀리기 과정을 진행하지 않습니다.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 정규화만 수행\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "       './image_data/test',      # 테스트셋이 있는 폴더의 위치입니다.\n",
    "       target_size=(150, 150),  # 이미지 크기\n",
    "       batch_size=5,\n",
    "       class_mode='binary')     # 치매 / 정상 이진 분류 이기 때문에 바이너리 모드로 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VGG16**\n",
    "- 이미지 분류 문제를 위한 딥러닝 모델 중 하나로, 옥스퍼드 대학교 연구팀에서 개발한 모델입니다. VGG16은 대규모 이미지 데이터셋인 ImageNet에서 사전 학습된 가중치를 활용하여 다양한 이미지 분류 작업에 유용하게 사용할 수 있습니다.\n",
    "  - weights='imagenet': \n",
    "    - 이 매개변수는 VGG16 모델의 가중치를 어떤 값으로 초기화할지를 결정합니다. 'imagenet'으로 설정하면 ImageNet 데이터셋에서 미리 학습한 가중치를 사용합니다. 이를 통해 모델이 이미지 분류 문제를 더 쉽게 학습할 수 있습니다.\n",
    "\n",
    "  - include_top=False: \n",
    "    - 이 매개변수는 VGG16의 최상위(fully connected) 계층(top)을 포함할지 여부를 결정합니다. True로 설정하면 VGG16 모델의 마지막 계층까지 포함하여 이미지 분류를 수행하는 모델이 생성되지만, False로 설정하면 VGG16의 최상위 계층을 제외한 부분만 생성됩니다. 주로 전이 학습(transfer learning)을 위해 사용되며, 사용자가 자신만의 분류기(classifier)를 추가하거나 다른 작업에 활용할 수 있도록 합니다.\n",
    "\n",
    "  - input_shape=(150, 150, 3): \n",
    "    - 입력 이미지의 크기를 정의하는 매개변수입니다. VGG16 모델은 입력으로 150x150 크기의 컬러(RGB) 이미지를 기대합니다. 따라서 이를 입력으로 사용하여 모델을 생성하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 9s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG16 모델을 불러옵니다.\n",
    "transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "transfer_model.trainable = False\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                524352    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15239105 (58.13 MB)\n",
      "Trainable params: 524417 (2.00 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "finetune_model = models.Sequential()\n",
    "finetune_model.add(transfer_model)\n",
    "finetune_model.add(Flatten())\n",
    "finetune_model.add(Dense(64))\n",
    "finetune_model.add(Activation('relu'))\n",
    "finetune_model.add(Dropout(0.5))\n",
    "finetune_model.add(Dense(1))\n",
    "finetune_model.add(Activation('sigmoid'))\n",
    "finetune_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 6s 154ms/step - loss: 0.7112 - accuracy: 0.5562 - val_loss: 0.5465 - val_accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.4903 - accuracy: 0.7500 - val_loss: 0.4488 - val_accuracy: 0.8400\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 0.4428 - accuracy: 0.8125 - val_loss: 0.4028 - val_accuracy: 0.8200\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 0.3890 - accuracy: 0.8375 - val_loss: 0.3640 - val_accuracy: 0.8400\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.3682 - accuracy: 0.8562 - val_loss: 0.3427 - val_accuracy: 0.8800\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.2853 - accuracy: 0.9250 - val_loss: 0.2319 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.2881 - accuracy: 0.9062 - val_loss: 0.2258 - val_accuracy: 0.9600\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.2718 - accuracy: 0.9250 - val_loss: 0.2476 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.2263 - accuracy: 0.9250 - val_loss: 0.1995 - val_accuracy: 0.9200\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.2253 - accuracy: 0.9312 - val_loss: 0.1619 - val_accuracy: 0.9400\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.2006 - accuracy: 0.9375 - val_loss: 0.2348 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.2228 - accuracy: 0.9000 - val_loss: 0.2664 - val_accuracy: 0.8400\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 5s 167ms/step - loss: 0.1814 - accuracy: 0.9375 - val_loss: 0.2181 - val_accuracy: 0.9400\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.1600 - accuracy: 0.9438 - val_loss: 0.2234 - val_accuracy: 0.9200\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 0.1585 - accuracy: 0.9438 - val_loss: 0.1248 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.1962 - accuracy: 0.9312 - val_loss: 0.0999 - val_accuracy: 0.9800\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.1502 - accuracy: 0.9500 - val_loss: 0.1260 - val_accuracy: 0.9800\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.1558 - accuracy: 0.9500 - val_loss: 0.1634 - val_accuracy: 0.9400\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.1406 - accuracy: 0.9438 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.1432 - accuracy: 0.9438 - val_loss: 0.2097 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# 모델의 실행 옵션을 설정합니다.\n",
    "finetune_model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
    "\n",
    "# 학습의 조기 중단을 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history = finetune_model.fit(\n",
    "       train_generator,\n",
    "       epochs=20,\n",
    "       validation_data=test_generator,\n",
    "       validation_steps=10,\n",
    "       callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증셋과 학습셋의 오차를 저장합니다.\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현해 봅니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시하겠습니다.\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
